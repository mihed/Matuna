\relax 
\bibstyle{unsrtnat}
\citation{convNetPicture}
\citation{convNetPicture}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Generalized CNN}{1}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces An example of a convolutional neural network \cite  {convNetPicture}. L stands for layer, the boxes corresponds to two dimensional images (maps) and the circles are perceptrons.}}{1}}
\newlabel{fig:convNet}{{1}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Fundamental Equations}{2}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Definitions and notations}}{2}}
\newlabel{tab:notations}{{1}{2}}
\newlabel{eq:abstractNetwork}{{1}{2}}
\newlabel{eq:fundamentalDeltaL}{{6}{3}}
\newlabel{eq:fundamentalDelta}{{7}{3}}
\newlabel{eq:fundamentalWeight}{{8}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}MLP}{3}}
\newlabel{eq:mlp}{{17}{4}}
\newlabel{eq:MLP_SSE_LINEAR}{{21}{4}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Common error functions.}}{6}}
\newlabel{tab:outputDeltaMLP}{{3.1}{6}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Output deltas for different activations and error functions.}}{6}}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Fundamental MLP equations.}}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Radial basis layer}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Convolution Layer}{8}}
\newlabel{remark:convolutionSubSamping}{{4}{9}}
\newlabel{eq:horrible}{{68}{9}}
\newlabel{eq:intermediateConvolution}{{69}{9}}
\newlabel{eq:simplifiedIntermediateConvolution}{{70}{10}}
\newlabel{eq:negativeConvolution}{{71}{10}}
\newlabel{eq:convolutionDeltaNeedsSimplification}{{73}{10}}
\newlabel{eq:convolutionDeltaSimplified}{{74}{10}}
\newlabel{eq:intermediateConvolutionSubSampling}{{75}{10}}
\newlabel{eq:weightConv}{{76}{11}}
\newlabel{eq:zConv}{{77}{11}}
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces Fundamental convolution equations.}}{12}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Pooling and Sub Sampling}{12}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.1}Weighed sub-sampling}{12}}
\newlabel{eq:subSampleDeltaComplex}{{91}{13}}
\@writefile{lot}{\contentsline {table}{\numberline {6}{\ignorespaces Fundamental weighed sub-sampling equations.}}{14}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.2}Max pooling}{14}}
\newlabel{eq:maxPooling}{{98}{14}}
\@writefile{lot}{\contentsline {table}{\numberline {7}{\ignorespaces Fundamental max-pooling equations.}}{15}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.3}Vanilla sub sampling}{15}}
\newlabel{eq:vanillaPooling}{{101}{15}}
\@writefile{lot}{\contentsline {table}{\numberline {8}{\ignorespaces Fundamental vanilla pooling equations.}}{15}}
\@writefile{toc}{\contentsline {section}{\numberline {4}LM Optimization}{15}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Multilayer Perceptron}{15}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Implementation Considerations}{17}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Gradient Descent}{18}}
\newlabel{eq:descentUpdate}{{118}{18}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Choosing $\mu _i$}{18}}
\newlabel{eq:lineSearch}{{119}{18}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Momentum}{19}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Conjugate Gradient}{19}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Conjugate Directions}{19}}
\newlabel{eq:diretionxUpdate}{{122}{19}}
\citation{conjugatedGradients}
\newlabel{eq:errorUpdateAlpha}{{123}{20}}
\newlabel{eq:residual}{{132}{20}}
\newlabel{eq:residualUpdate}{{134}{20}}
\newlabel{eq:errorUpdate}{{135}{20}}
\newlabel{eq:alpha}{{139}{20}}
\newlabel{eq:gammaAlpha}{{147}{21}}
\newlabel{eq:directionConstruction}{{148}{21}}
\newlabel{eq:betaEquation}{{149}{21}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Conjugated Gradient}{22}}
\newlabel{eq:krylovSubspace}{{150}{22}}
\newlabel{eq:simplifiedBeta}{{154}{22}}
\newlabel{eq:gradientStart}{{156}{22}}
\newlabel{eq:gradientAlpha}{{157}{22}}
\newlabel{eq:gradientX}{{158}{22}}
\newlabel{eq:gradientR}{{159}{22}}
\newlabel{eq:gradientBeta}{{160}{23}}
\newlabel{eq:gradientD}{{161}{23}}
\newlabel{eq:taylorApproximation}{{163}{23}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3}Implementation Consideration}{23}}
\@writefile{toc}{\contentsline {section}{\numberline {7}BFGS}{24}}
\newlabel{eq:taylorExpansion}{{170}{24}}
\newlabel{eq:taylorSimplified}{{171}{24}}
\newlabel{eq:bfgsDirectionUpdate}{{172}{24}}
\newlabel{eq:updateBFGS}{{173}{24}}
\newlabel{eq:secantEquation}{{176}{24}}
\newlabel{eq:curvatureCondition}{{177}{24}}
\@writefile{loa}{\contentsline {algocf}{\numberline {1}{\ignorespaces BFGS}}{25}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1}L-BFGS}{26}}
\newlabel{eq:hessianUpdate}{{186}{26}}
\@writefile{loa}{\contentsline {algocf}{\numberline {2}{\ignorespaces L-BFGS (Two-loop)}}{26}}
\newlabel{alg:LBFGSTwoLoop}{{2}{26}}
\@writefile{loa}{\contentsline {algocf}{\numberline {3}{\ignorespaces L-BFGS}}{27}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2}Implementation Considerations}{27}}
\@writefile{toc}{\contentsline {section}{\numberline {8}Ideas}{28}}
\@writefile{toc}{\contentsline {section}{\numberline {9}Software Implementation}{28}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Showing the execution time of a convolutional layer using a single kernel and multiple kernel launches. Full means a fully connected convolutional layer with 4 inputs and 8 outputs. Single means single connections between 4 inputs and 4 outputs}}{30}}
\newlabel{fig:intelGPUKernelLaunch}{{2}{30}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Showing the execution time of a convolutional layer using a single kernel and multiple kernel launches. Full means a fully connected convolutional layer with 4 inputs and 8 outputs. Single means single connections between 4 inputs and 4 outputs}}{30}}
\newlabel{fig:nvidiaGPUKernelLaunch}{{3}{30}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Showing the execution time of a convolutional layer using a single kernel and multiple kernel launches. Full means a fully connected convolutional layer with 4 inputs and 8 outputs. Single means single connections between 4 inputs and 4 outputs}}{31}}
\newlabel{fig:cpuKernelLaunch}{{4}{31}}
\@writefile{toc}{\contentsline {section}{\numberline {10}Automatically tuned OpenCL kernels}{32}}
\@writefile{lot}{\contentsline {table}{\numberline {9}{\ignorespaces Fundamental weighed sub-sampling equations.}}{32}}
\@writefile{toc}{\contentsline {subsection}{\numberline {10.1}Convolutional layer}{32}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {10.1.1}CPU}{32}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {10.1.2}GPU}{32}}
\bibdata{sample}
\bibcite{convNetPicture}{{1}{}{{con}}{{}}}
\@writefile{loa}{\contentsline {algocf}{\numberline {4}{\ignorespaces Calculates the optimal work size and padding with minimal global memory access.}}{35}}
\bibcite{conjugatedGradients}{{2}{}{{con}}{{}}}
\@writefile{toc}{\contentsline {subsection}{\numberline {10.2}Pooling layer}{36}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {10.2.1}CPU}{36}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {10.2.2}GPU}{36}}
\@writefile{toc}{\contentsline {subsection}{\numberline {10.3}Perceptron layer}{36}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {10.3.1}CPU}{36}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {10.3.2}GPU}{36}}
